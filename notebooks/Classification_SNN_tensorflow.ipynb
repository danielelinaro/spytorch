{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f31cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import RandomState, SeedSequence, MT19937\n",
    "from scipy.stats import expon, norm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "panel_w, panel_h = 2, 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a83a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_voltage_traces(Vm, spikes=None, dim=(4,4), spike_height=5):\n",
    "    rows,cols = dim\n",
    "    fig,ax = plt.subplots(rows, cols, figsize=(cols*panel_w, rows*panel_h), sharex=True, sharey=True)\n",
    "    if spikes is not None:\n",
    "        data = 1.0 * Vm # make a copy of Vm\n",
    "        data[spikes > 0.0] = spike_height\n",
    "    else:\n",
    "        data = Vm\n",
    "    idx = np.linspace(0, len(Vm), rows*cols, endpoint=False, dtype=int)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            k = i*dim[1] + j\n",
    "            ax[i,j].plot(data[idx[k]], lw=1)\n",
    "            ax[i,j].grid(which='major', axis='y', lw=0.5, ls=':', color=[.6,.6,.6])\n",
    "            sns.despine()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f7880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spikes(spikes, dim=(4,4)):\n",
    "    rows,cols = dim\n",
    "    idx = np.linspace(0, spikes.shape[0], rows*cols, endpoint=False, dtype=int)\n",
    "    fig,ax = plt.subplots(rows, cols, figsize=(cols*panel_w, rows*panel_h), sharex=True, sharey=True)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            k = i*cols + j\n",
    "            ax[i][j].imshow(spikes[idx[k]], cmap=plt.cm.gray_r, aspect='auto')\n",
    "            sns.despine()\n",
    "    for a in ax[-1,:]:\n",
    "        a.set_xlabel('Time (ms)')\n",
    "    for a in ax[:,0]:\n",
    "        a.set_ylabel('Unit')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981f7fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_leaky_nn(inputs, weights, dtype=tf.float32):\n",
    "    batch_size, _, n_steps = inputs.shape\n",
    "    n_inputs, n_outputs = weights.shape\n",
    "    I_inp = tf.einsum('abc,bd->acd', inputs, weights)\n",
    "    I_syn_curr = tf.zeros((batch_size, n_outputs), dtype=dtype)\n",
    "    Vm_curr = tf.zeros((batch_size, n_outputs), dtype=dtype)\n",
    "    Vm = []\n",
    "    for t in range(n_steps):\n",
    "        Vm.append(Vm_curr)\n",
    "        I_syn_next = alpha * I_syn_curr + I_inp[:,t,:]\n",
    "        Vm_next = beta * Vm_curr + I_syn_curr\n",
    "        I_syn_curr = I_syn_next\n",
    "        Vm_curr = Vm_next\n",
    "    Vm = tf.stack(Vm, axis=1)\n",
    "    return Vm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b654780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_spiking_nn(inputs, weigths, thresh=1., dtype=tf.float32):\n",
    "    heaviside = lambda x, thresh=0.: 0.5 * (1 + (x-thresh) / tf.sqrt((x-thresh)**2))\n",
    "    I_inp = tf.einsum('abc,bd->acd', inputs, weights)\n",
    "    I_syn_curr = tf.zeros((batch_size, n_outputs), dtype=dtype)\n",
    "    Vm_curr = tf.zeros((batch_size, n_outputs), dtype=dtype)\n",
    "    Vm = []\n",
    "    spikes = []\n",
    "    for t in range(n_steps):\n",
    "        reset = heaviside(Vm_curr, thresh)\n",
    "        I_syn_next = alpha * I_syn_curr + I_inp[:,t,:]\n",
    "        Vm_next = beta * Vm_curr + I_syn_curr - reset\n",
    "        Vm.append(Vm_curr)\n",
    "        spikes.append(reset)\n",
    "        I_syn_curr = I_syn_next\n",
    "        Vm_curr = Vm_next\n",
    "    Vm = tf.stack(Vm, axis=1)\n",
    "    spikes = tf.stack(spikes, axis=1)\n",
    "    return Vm, spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf63610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RandomState(MT19937(SeedSequence(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30deae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiking = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dda218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron parameters\n",
    "tau_mem    = 10e-3\n",
    "tau_syn    = 5e-3\n",
    "# network parameters\n",
    "input_rate = 10 # [Hz]\n",
    "n_inputs   = 50\n",
    "n_outputs  = 2\n",
    "# simulation parameters\n",
    "tend       = 0.2\n",
    "dt         = 1e-3\n",
    "n_steps    = int(tend / dt)\n",
    "# batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca62a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 10\n",
    "half_inputs = n_inputs // 2\n",
    "rv = expon()\n",
    "ISI = expon.rvs(scale=1/input_rate,\n",
    "                size=(batch_size, half_inputs, int(np.ceil(tend * input_rate))),\n",
    "                random_state=rs)\n",
    "spike_times_fast = np.cumsum(ISI, axis=-1)\n",
    "ISI = expon.rvs(scale=1/(input_rate/scale),\n",
    "                size=(batch_size, half_inputs, int(np.ceil(tend * input_rate / scale))),\n",
    "                random_state=rs)\n",
    "spike_times_slow = np.cumsum(ISI, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54786dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.zeros((batch_size, n_inputs, n_steps), dtype=np.float32)\n",
    "half_batches = batch_size // 2\n",
    "for i in range(batch_size):\n",
    "    for j in range(half_inputs):\n",
    "        idx_fast = np.floor(spike_times_fast[i,j,:] / dt).astype(int)\n",
    "        idx_fast = idx_fast[idx_fast < n_steps]\n",
    "        idx_slow = np.floor(spike_times_slow[i,j,:] / dt).astype(int)\n",
    "        idx_slow = idx_slow[idx_slow < n_steps]\n",
    "        if i < half_batches:\n",
    "            inputs[i, j, idx_fast] = 1\n",
    "            inputs[i, j+half_inputs, idx_slow] = 1\n",
    "        else:\n",
    "            inputs[i, j, idx_slow] = 1\n",
    "            inputs[i, j+half_inputs, idx_fast] = 1\n",
    "print(f'Total number of input spikes: {inputs.sum():.0f}.')\n",
    "# inputs = tf.Variable(inputs, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d381e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_spikes(inputs)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff82f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = np.zeros((batch_size,1))\n",
    "truth[:half_batches] = 1\n",
    "enc = OneHotEncoder()\n",
    "y = enc.fit(truth).transform(truth).toarray().astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha   = float(np.exp(-dt/tau_syn))\n",
    "beta    = float(np.exp(-dt/tau_mem))\n",
    "weight_scale = 7 * (1 - beta)\n",
    "μ = 0\n",
    "weights = np.zeros((n_inputs, n_outputs))\n",
    "weights[:half_inputs, 0] = norm.rvs(loc=μ, scale=weight_scale/np.sqrt(n_inputs),\n",
    "                                    size=half_inputs, random_state=rs)\n",
    "weights[half_inputs:, 0] = norm.rvs(loc=-μ, scale=weight_scale/np.sqrt(n_inputs),\n",
    "                                    size=half_inputs, random_state=rs)\n",
    "weights[:half_inputs, 1] = norm.rvs(loc=μ, scale=weight_scale/np.sqrt(n_inputs),\n",
    "                                    size=half_inputs, random_state=rs)\n",
    "weights[half_inputs:, 1] = norm.rvs(loc=-μ, scale=weight_scale/np.sqrt(n_inputs),\n",
    "                                    size=half_inputs, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ece0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = tf.float32\n",
    "inputs_tf = tf.constant(inputs, dtype=dtype)\n",
    "weights_tf = tf.Variable(weights, dtype=dtype, trainable=True)\n",
    "y_tf = tf.constant(y, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbc40a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if spiking:\n",
    "    Vm,spikes = run_spiking_nn(inputs_tf, weights_tf, dtype=dtype)\n",
    "    fig = plot_voltage_traces(Vm.numpy(), spikes.numpy())\n",
    "else:\n",
    "    Vm = run_leaky_nn(inputs_tf, weights_tf, dtype=dtype)\n",
    "    fig = plot_voltage_traces(Vm.numpy())\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ecbeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if spiking:\n",
    "    output = tf.transpose(spikes, perm=(0, 2, 1)).numpy()\n",
    "    fig = plot_spikes(output)\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1e9ba6e",
   "metadata": {},
   "source": [
    "Vm = run_leaky_nn(inputs_tf, weights_tf, dtype=dtype)\n",
    "# either this:\n",
    "loss_fun = tf.nn.softmax_cross_entropy_with_logits\n",
    "loss = tf.math.reduce_sum(loss_fun(labels=y_tf, logits=tf.math.reduce_mean(Vm, axis=1)))\n",
    "# or this:\n",
    "# y_hat = tf.nn.softmax(tf.math.reduce_mean(Vm, axis=1), axis=1)\n",
    "# loss_fun = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.SUM)\n",
    "# loss = loss_fun(y, y_hat)\n",
    "print(f'Loss: {loss:g}.')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "542e77d6",
   "metadata": {},
   "source": [
    "Vm,spikes = run_spiking_nn(inputs_tf, weights_tf, dtype=dtype)\n",
    "loss_fun = tf.nn.softmax_cross_entropy_with_logits\n",
    "loss = tf.math.reduce_sum(loss_fun(labels=y_tf, logits=tf.math.reduce_sum(spikes, axis=1)))\n",
    "print(f'Loss: {loss:g}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b72cc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fun = tf.nn.softmax_cross_entropy_with_logits\n",
    "with tf.GradientTape() as tape:\n",
    "    if spiking:\n",
    "        Vm,spikes = run_spiking_nn(inputs_tf, weights_tf, dtype=dtype)\n",
    "        y_hat = tf.math.reduce_sum(spikes, axis=1)\n",
    "    else:\n",
    "        Vm = run_leaky_nn(inputs_tf, weights_tf, dtype=dtype)\n",
    "        y_hat = tf.math.reduce_mean(Vm, axis=1)\n",
    "    loss = tf.math.reduce_sum(loss_fun(labels=y_tf, logits=y_hat))\n",
    "grad = tape.gradient(loss, [weights_tf])\n",
    "print(f'Loss: {loss:g}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da2e767",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-3, beta_1=0.9, beta_2=0.999)\n",
    "loss_fun = tf.nn.softmax_cross_entropy_with_logits\n",
    "loss_hist = []\n",
    "n_epochs = 500\n",
    "for e in tqdm(range(n_epochs)):\n",
    "    with tf.GradientTape(persistent=False) as tape:\n",
    "        if spiking:\n",
    "            _,spikes = run_spiking_nn(inputs_tf, weights_tf, dtype=dtype)\n",
    "            y_hat = tf.math.reduce_sum(spikes, axis=1)\n",
    "        else:\n",
    "            Vm = run_leaky_nn(inputs_tf, weights_tf, dtype=dtype) \n",
    "            y_hat = tf.math.reduce_mean(Vm, axis=1)\n",
    "        # compute the loss\n",
    "        loss = tf.math.reduce_sum(loss_fun(labels=y_tf, logits=y_hat))\n",
    "    # compute the gradient\n",
    "    grad = tape.gradient(loss, [weights_tf])\n",
    "    # update the weights\n",
    "    optimizer.apply_gradients(zip(grad, [weights_tf]))\n",
    "    # store loss value\n",
    "    loss_hist.append(loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcdf521",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 1, figsize=(4,3))\n",
    "ax.plot(loss_hist, color='k')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.grid(which='major', axis='y', lw=0.5, ls=':', color=[.6,.6,.6])\n",
    "sns.despine()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684e6fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if spiking:\n",
    "    Vm,spikes = run_spiking_nn(inputs_tf, weights_tf, dtype=dtype)\n",
    "    fig = plot_voltage_traces(Vm.numpy(), spikes.numpy())\n",
    "else:\n",
    "    Vm = run_leaky_nn(inputs_tf, weights_tf, dtype=dtype)\n",
    "    fig = plot_voltage_traces(Vm.numpy())\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1325d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if spiking:\n",
    "    output = tf.transpose(spikes, perm=(0, 2, 1)).numpy()\n",
    "    fig = plot_spikes(output)\n",
    "    fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
